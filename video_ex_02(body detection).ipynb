{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#얼굴 탐지\n",
    "conda_path = 'C:\\\\Users\\\\BIT-USER\\\\Anaconda3\\\\Library\\\\etc\\\\haarcascades\\\\'\n",
    "face_cascade = cv2.CascadeClassifier(conda_path + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('moms.mp4')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation = cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        face_rects = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "\n",
    "        for(x, y, w, h) in face_rects:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 3)\n",
    "\n",
    "        cv2.imshow('Face Detector', frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홍채 탐지 (영상 / 안됨)\n",
    "import math\n",
    "\n",
    "cap = cv2.VideoCapture('face_close_up.mp4')\n",
    "scaling_factor = 0.7\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation = cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ret, thresh_gray = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)\n",
    "        image, contours, hierarchy = cv2.findContours(thresh_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "        \n",
    "        for contour in contours :\n",
    "            area = cv2.contourArea(contour)\n",
    "            rect = cv2.boundingRect(contour)\n",
    "            x, y, width, height = rect\n",
    "            radius = 0.25 * (width + height)\n",
    "            \n",
    "            area_condition = (100 <= area <= 200)\n",
    "            symmetry_condition = (abs(1 - float(width) / float(height)) <= 0.2)\n",
    "            fill_condition = (abs(1 - (area / (math.pi * math.pow(radius, 2.0)))) <= 0.3)\n",
    "            \n",
    "            if area_condition and symmetry_condition and fill_condition:\n",
    "                cv2.circle(frame, (int(x + radius), int(y + radius)), int(1.3*radius), (0, 180, 0), -1)\n",
    "        \n",
    "        cv2.imshow('Iris Detector', frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    else :\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홍채 탐지(이미지 / 안됨)\n",
    "import math\n",
    "\n",
    "img = cv2.imread('face.jpg')\n",
    "scaling_factor = 0.7\n",
    "\n",
    "#img = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation = cv2.INTER_AREA)\n",
    "gray = cv2.cvtColor(~img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "ret, thresh_gray = cv2.threshold(gray, 220, 255, cv2.THRESH_BINARY)\n",
    "image, contours, hierarchy = cv2.findContours(thresh_gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "for contour in contours :\n",
    "    area = cv2.contourArea(contour) # 면적 계산\n",
    "    rect = cv2.boundingRect(contour)\n",
    "    x, y, width, height = rect\n",
    "    radius = 0.25 * (width + height)\n",
    "\n",
    "    area_condition = (100 <= area <= 200)\n",
    "    symmetry_condition = (abs(1 - float(width) / float(height)) <= 0.2) # 대칭\n",
    "    fill_condition = (abs(1 - (area / (math.pi * math.pow(radius, 2.0)))) <= 0.3)\n",
    "\n",
    "    if area_condition and symmetry_condition and fill_condition:\n",
    "        cv2.circle(img, (int(x + radius), int(y + radius)), int(1.3*radius), (0, 180, 0), -1)\n",
    "\n",
    "cv2.imshow('Iris Detector', img)\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#얼굴 인식해서 그 부분만 두 배로 만들기\n",
    "conda_path = 'C:\\\\Users\\\\BIT-USER\\\\Anaconda3\\\\Library\\\\etc\\\\haarcascades\\\\'\n",
    "upper_cascade = cv2.CascadeClassifier(conda_path + 'haarcascade_frontalface_default.xml') # haarcascade_frontalface_default\n",
    "\n",
    "img = cv2.imread('face.jpg')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "frame = cv2.resize(img, None, fx=scaling_factor, fy=scaling_factor, interpolation = cv2.INTER_AREA)\n",
    "gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "upper_rects = upper_cascade.detectMultiScale(gray, 1.1, 2) # \n",
    "\n",
    "copy_x=0\n",
    "copy_y=0\n",
    "copy_w=0\n",
    "copy_h=0\n",
    "\n",
    "for(x, y, w, h) in upper_rects:\n",
    "    cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "    copy_x = x\n",
    "    copy_y = y\n",
    "    copy_w = w\n",
    "    copy_h = h\n",
    "\n",
    "frame1 = frame[copy_y : copy_y+copy_h, copy_x : copy_x+copy_w]\n",
    "height, width = frame1.shape[:2]\n",
    "\n",
    "frame1 = cv2.resize(frame1, (2*width, 2*height), interpolation = cv2.INTER_CUBIC) #2배로 만들기\n",
    "\n",
    "cv2.imshow('Face Detector', frame1)\n",
    "\n",
    "cv2.waitKey(0)        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상체 탐지(영상)\n",
    "conda_path = 'C:\\\\Users\\\\BIT-USER\\\\Anaconda3\\\\Library\\\\etc\\\\haarcascades\\\\'\n",
    "upper_cascade = cv2.CascadeClassifier(conda_path + 'haarcascade_upperbody.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('i_p.mp4')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame = cv2.resize(frame, None, fx=scaling_factor, fy=scaling_factor, interpolation = cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        upper_rects = upper_cascade.detectMultiScale(gray, 1.1, 8)\n",
    "\n",
    "        for(x, y, w, h) in upper_rects:\n",
    "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "\n",
    "        cv2.imshow('Face Detector', frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\BIT-USER\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:12: DeprecationWarning: elementwise != comparison failed; this will raise an error in the future.\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "# 상체인식(이미지)\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "img = cv2.imread('interviewers.jpg',0)\n",
    "\n",
    "conda_path = 'C:\\\\Users\\\\BIT-USER\\\\Anaconda3\\\\Library\\\\etc\\\\haarcascades\\\\'\n",
    "upperBody_cascade = cv2.CascadeClassifier(conda_path + 'haarcascade_upperbody.xml')    \n",
    "\n",
    "arrUpperBody = upperBody_cascade.detectMultiScale(img, 1.1, 2)\n",
    "\n",
    "if arrUpperBody != ():\n",
    "        for (x,y,w,h) in arrUpperBody:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
    "\n",
    "cv2.imshow('image',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 홍채 인식 안됨\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "cap = cv2.VideoCapture('ddoddo.mp4') \t#640,480\n",
    "conda_path = 'C:\\\\Users\\\\BIT-USER\\\\Anaconda3\\\\Library\\\\etc\\\\haarcascades\\\\'\n",
    "faces = cv2.CascadeClassifier(conda_path + 'haarcascade_frontalface_default.xml')  \n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        #detect face\n",
    "        frame = cv2.cvtColor(frame,cv2.COLOR_RGB2GRAY)\n",
    "        detected = faces.detectMultiScale(frame, 1.3, 5)\n",
    "            \n",
    "        pupilFrame = frame\n",
    "        windowClose = np.ones((5,5),np.uint8)\n",
    "        windowOpen = np.ones((2,2),np.uint8)\n",
    "        windowErode = np.ones((2,2),np.uint8)\n",
    "\n",
    "        #draw square\n",
    "        for (x,y,w,h) in detected:\n",
    "            cv2.rectangle(frame, (x,y), ((x+w),(y+h)), (0,0,255),1)\t\n",
    "            cv2.line(frame, (x,y), ((x+w,y+h)), (0,0,255),1)\n",
    "            cv2.line(frame, (x+w,y), ((x,y+h)), (0,0,255),1)\n",
    "            pupilFrame = cv2.equalizeHist(frame[y+(h*.25):(y+h), x:(x+w)])\n",
    "            pupilO = pupilFrame\n",
    "            ret, pupilFrame = cv2.threshold(pupilFrame,55,255,cv2.THRESH_BINARY)\t\t#50 ..nothin 70 is better\n",
    "            pupilFrame = cv2.morphologyEx(pupilFrame, cv2.MORPH_CLOSE, windowClose)\n",
    "            pupilFrame = cv2.morphologyEx(pupilFrame, cv2.MORPH_ERODE, windowErode)\n",
    "            pupilFrame = cv2.morphologyEx(pupilFrame, cv2.MORPH_OPEN, windowOpen)\n",
    "\n",
    "            #so above we do image processing to get the pupil..\n",
    "            #now we find the biggest blob and get the centriod\n",
    "            \n",
    "            threshold = cv2.inRange(pupilFrame,250,255)\t\t#get the blobs\n",
    "            contours, hierarchy = cv2.findContours(threshold,cv2.RETR_LIST,cv2.CHAIN_APPROX_SIMPLE)\n",
    "            \n",
    "            #if there are 3 or more blobs, delete the biggest and delete the left most for the right eye\n",
    "            #if there are 2 blob, take the second largest\n",
    "            #if there are 1 or less blobs, do nothing\n",
    "            \n",
    "            if len(contours) >= 2:\n",
    "                #find biggest blob\n",
    "                maxArea = 0\n",
    "                MAindex = 0\t\t\t#to get the unwanted frame \n",
    "                distanceX = []\t\t#delete the left most (for right eye)\n",
    "                currentIndex = 0 \n",
    "                for cnt in contours:\n",
    "                    area = cv2.contourArea(cnt)\n",
    "                    center = cv2.moments(cnt)\n",
    "                    cx,cy = int(center['m10']/center['m00']), int(center['m01']/center['m00'])\n",
    "                    distanceX.append(cx)\t\n",
    "                    if area > maxArea:\n",
    "                        maxArea = area\n",
    "                        MAindex = currentIndex\n",
    "                    currentIndex = currentIndex + 1\n",
    "\n",
    "                del contours[MAindex]\t\t#remove the picture frame contour\n",
    "                del distanceX[MAindex]\n",
    "\n",
    "            eye = 'right'\n",
    "\n",
    "            if len(contours) >= 2:\t\t#delete the left most blob for right eye\n",
    "                if eye == 'right':\n",
    "                    edgeOfEye = distanceX.index(min(distanceX))\n",
    "                else:\n",
    "                    edgeOfEye = distanceX.index(max(distanceX))\t\n",
    "                del contours[edgeOfEye]\n",
    "                del distanceX[edgeOfEye]\n",
    "\n",
    "            if len(contours) >= 1:\t\t#get largest blob\n",
    "                maxArea = 0\n",
    "                for cnt in contours:\n",
    "                    area = cv2.contourArea(cnt)\n",
    "                    if area > maxArea:\n",
    "                        maxArea = area\n",
    "                        largeBlob = cnt\n",
    "                    \n",
    "            if len(largeBlob) > 0:\t\n",
    "                center = cv2.moments(largeBlob)\n",
    "                cx,cy = int(center['m10']/center['m00']), int(center['m01']/center['m00'])\n",
    "                cv2.circle(pupilO,(cx,cy),5,255,-1)\n",
    "\n",
    "        cv2.imshow('frame2',pupilFrame)\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Region Proposals: 0\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import sys\n",
    "import cv2\n",
    "\n",
    "# speed-up using multithreads\n",
    "cv2.setUseOptimized(True);\n",
    "cv2.setNumThreads(4);\n",
    "\n",
    "# read image\n",
    "im = cv2.imread('taylor.jpg')\n",
    "# resize image\n",
    "# newHeight = 200\n",
    "# newWidth = int(im.shape[1]*200/im.shape[0])\n",
    "# im = cv2.resize(im, (newWidth, newHeight))    \n",
    "\n",
    "# create Selective Search Segmentation Object using default parameters\n",
    "ss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\n",
    "# set input image on which we will run segmentation\n",
    "ss.setBaseImage(im)\n",
    "\n",
    "# run selective search segmentation on input image\n",
    "rects = ss.process()\n",
    "print('Total Number of Region Proposals: {}'.format(len(rects)))\n",
    "\n",
    "# number of region proposals to show\n",
    "numShowRects = 100\n",
    "# increment to increase/decrease total number\n",
    "# of reason proposals to be shown\n",
    "increment = 50\n",
    "\n",
    "while True:\n",
    "    # create a copy of original image\n",
    "    imOut = im.copy()\n",
    "\n",
    "    # itereate over all the region proposals\n",
    "    for i, rect in enumerate(rects):\n",
    "        # draw rectangle for region proposal till numShowRects\n",
    "        if (i < numShowRects):\n",
    "            x, y, w, h = rect\n",
    "            cv2.rectangle(imOut, (x, y), (x+w, y+h), (0, 255, 0), 1, cv2.LINE_AA)\n",
    "        else:\n",
    "            break\n",
    "\n",
    "    # show output\n",
    "    cv2.imshow(\"Output\", imOut)\n",
    "\n",
    "    # record key press\n",
    "    k = cv2.waitKey(0) & 0xFF\n",
    "\n",
    "    # m is pressed\n",
    "    if k == 109:\n",
    "        # increase total number of rectangles to show by increment\n",
    "        numShowRects += increment\n",
    "    # l is pressed\n",
    "    elif k == 108 and numShowRects > increment:\n",
    "        # decrease total number of rectangles to show by increment\n",
    "        numShowRects -= increment\n",
    "    # q is pressed\n",
    "    elif k == 113:\n",
    "        break\n",
    "# close image show window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#영상 합치기 & 저장\n",
    "\n",
    "cap = cv2.VideoCapture('moms.mp4')\n",
    "cap2 = cv2.VideoCapture('moms.mp4')\n",
    "\n",
    "w = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "h = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv2.VideoWriter_fourcc(*'DIVX')\n",
    "out = cv2.VideoWriter('output.mp4',fourcc, 20.0, (int(w), int(h)))\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    ret2, frame2 = cap2.read()\n",
    "\n",
    "    if ret:\n",
    "        frame2 = cv2.resize(frame2, None, fx=0.25, fy=0.25, interpolation = cv2.INTER_CUBIC)\n",
    "\n",
    "        height = frame2.shape[0]\n",
    "        width = frame2.shape[1]\n",
    "\n",
    "        frame1[100:100+height, 100:100+width] = frame2[:height, :width]\n",
    "        \n",
    "        out.write(frame1)\n",
    "\n",
    "        cv2.imshow('frame',frame1)\n",
    "\n",
    "        if cv2.waitKey(50) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#상체 탐지(영상) + 확대해서 영상에 보이기\n",
    "conda_path = 'C:\\\\Users\\\\BIT-USER\\\\Anaconda3\\\\Library\\\\etc\\\\haarcascades\\\\'\n",
    "upper_cascade = cv2.CascadeClassifier(conda_path + 'haarcascade_upperbody.xml')\n",
    "\n",
    "cap = cv2.VideoCapture('i_p.mp4')\n",
    "scaling_factor = 0.5\n",
    "\n",
    "width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "\n",
    "while True:\n",
    "    ret, frame1 = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        frame1 = cv2.resize(frame1, None, fx=scaling_factor, fy=scaling_factor, interpolation = cv2.INTER_AREA)\n",
    "        gray = cv2.cvtColor(frame1, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        upper_rects = upper_cascade.detectMultiScale(gray, 1.1, 1)\n",
    "        \n",
    "        copy_x=0\n",
    "        copy_y=0\n",
    "        copy_w=0\n",
    "        copy_h=0\n",
    "\n",
    "        for(x, y, w, h) in upper_rects:\n",
    "            cv2.rectangle(frame1, (x, y), (x+w, y+h), (0, 255, 0), 0)\n",
    "            copy_x = x\n",
    "            copy_y = y\n",
    "            copy_w = w\n",
    "            copy_h = h\n",
    "        \n",
    "            frame2 = frame1[copy_y : copy_y+copy_h, copy_x : copy_x+copy_w]\n",
    "\n",
    "            frame2 = cv2.resize(frame2, (2*frame2.shape[0], 2*frame2.shape[1]), interpolation = cv2.INTER_CUBIC) #2배로 만들기\n",
    "\n",
    "            frame1[100:100+frame2.shape[0], 100:100+frame2.shape[1]] = frame2[:frame2.shape[0], :frame2.shape[1]]\n",
    "            \n",
    "        cv2.imshow('Face Detector', frame1)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
